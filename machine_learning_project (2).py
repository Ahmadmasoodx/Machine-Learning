# -*- coding: utf-8 -*-
"""Machine Learning Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e3qX5jUeY_NqstItTGSkRHsZK0h5POdn
"""

import pandas as pd

from google.colab import drive

drive.mount('/content/drive')

#Reading csv file
path=("/content/carclaims.csv")  
Dataframe=pd.read_csv(path)

#df=pd.read_csv(path)

Dataframe.head(5)
#Dataframe.schema.names

rows=Dataframe.count()
rows

#Checking null values
Dataframe.isnull().values.any()

#Checking Duplicate Values 
Dataframe.duplicated().values.any()

#Dataframe.replace('no change',0)

#Histogram to overview fraud found or not in dataset
import matplotlib.pyplot as plt
Dataframe["FraudFound"].hist(bins=5)
plt.show()

#Converting categorical features to numerical ones

#Dataframe['Month'] =Dataframe['Month'].astype('category').cat.codes
V=['Month','DayOfWeek','Make','AccidentArea','DayOfWeekClaimed','MonthClaimed','WeekOfMonthClaimed','Sex','MaritalStatus','Fault','PolicyType','VehicleCategory','VehiclePrice','Days:Policy-Accident','Days:Policy-Claim','PastNumberOfClaims','AgeOfVehicle','AgeOfPolicyHolder','PoliceReportFiled','WitnessPresent','AgentType','NumberOfSuppliments','AddressChange-Claim','NumberOfCars','BasePolicy','FraudFound']
for i in V:
  Dataframe[i] =Dataframe[i].astype('category').cat.codes
Dataframe

#Checking Correlation between independent variables and target variable

correlation_matrix = Dataframe.corr()
correlation_matrix['FraudFound']

#Dropping all columns with very low correlation

Drop=['Month','WeekOfMonth','WeekOfMonthClaimed','Age','PolicyNumber','RepNumber','DayOfWeek','Make','AccidentArea','DayOfWeekClaimed','MonthClaimed','WeekOfMonthClaimed','Fault','PolicyType','VehicleCategory','Days:Policy-Claim','AgeOfVehicle','AgeOfPolicyHolder','PoliceReportFiled','WitnessPresent','AgentType','AddressChange-Claim','BasePolicy']
zz=(["DayOfWeek","Month","WeekOfMonth","WeekOfMonthClaimed","Make","AccidentArea","RepNumber","Year","Age","PolicyNumber","DayOfWeekClaimed","MonthClaimed","Fault","PolicyType","VehicleCategory","Days:Policy-Claim","AgeOfVehicle","AgeOfPolicyHolder","PoliceReportFiled","WitnessPresent","AgentType",'AddressChange-Claim','BasePolicy'])
Dataframe=Dataframe.drop(zz,axis=1)


Dataframe.columns

#Dealing with imbalance dataset 

# class count
class_count_0, class_count_1 = Dataframe['FraudFound'].value_counts()

# Separate class
class_0 = Dataframe[Dataframe['FraudFound'] == 0]
class_1 = Dataframe[Dataframe['FraudFound'] == 1]
print('class 0:', class_0.shape)
print('class 1:', class_1.shape)

class_0_under = class_0.sample(class_count_1)

test_under = pd.concat([class_0_under, class_1], axis=0)

print("total class of 1 and0:",test_under['FraudFound'].value_counts())# plot the count after under-sampeling
test_under['FraudFound'].value_counts().plot(kind='bar', title='count (target)')

class_1.count()

class_0_under.count()

import pandas as pd
Dataframe=pd.concat([class_1,class_0_under])
Dataframe

correlation_matrix = Dataframe.corr()
correlation_matrix['FraudFound']

#Storing independent variables in X and targer variable in y

X = Dataframe.drop("FraudFound", axis=1)
X = X.values
y = Dataframe["FraudFound"]
y = y.values

#Creating new array with new data
import numpy as np
newVar=np.array([0,1,2,400,1,3,0,1,1])

#Finding distance bw new data point and data points in previous dataframe
distances = np.linalg.norm(X - newVar, axis=1)
#distances

#Finding 3 closest neighbours
k = 3
nearest_neighbor_ids = distances.argsort()[:k]
nearest_neighbor_ids

nearest_neighbor_rings = y[nearest_neighbor_ids]
nearest_neighbor_rings

import scipy.stats
scipy.stats.mode(nearest_neighbor_rings)

#Splitting data in training and test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12345)

#Fitting the model

from sklearn.neighbors import KNeighborsClassifier
knn_model = KNeighborsClassifier(n_neighbors=3)
knn_model.fit(X_train, y_train)

#Finding RMSE
from sklearn.metrics import mean_squared_error
from math import sqrt
train_preds = knn_model.predict(X_train)
mse = mean_squared_error(y_train, train_preds)
rmse = sqrt(mse)
rmse

#Predicting and checking RMSE
test_preds = knn_model.predict(X_test)
mse = mean_squared_error(y_test, test_preds)
rmse = sqrt(mse)
rmse

from sklearn import metrics
confusion_matrix = metrics.confusion_matrix(y_test, test_preds)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])
import matplotlib.pyplot as plt
cm_display.plot()
plt.show()

print("Accuracy:",metrics.accuracy_score(y_test, test_preds))

#If you observe a relatively large difference between the RMSE on the training data and the RMSE on the test data,
#this means that the model suffers from overfitting on the training data and it does not generalize well.

import seaborn as sns
cmap = sns.cubehelix_palette(as_cmap=True)
f, ax = plt.subplots()
points = ax.scatter(X_test[:, 2], X_test[:, 4], c=test_preds, s=50, cmap=cmap)
f.colorbar(points)
plt.show()
#This scatter pot shows ratio of fraud found with Vehicle Price and Driver rating in x and y axis respectively

#Improving KNN performance using Gridsearchcv
from sklearn.model_selection import GridSearchCV
parameters = {"n_neighbors": range(1, 50)}
gridsearch = GridSearchCV(KNeighborsClassifier(), parameters)
gridsearch.fit(X_train, y_train)

#Took more time to fit

#Printing the parameters that have lowest error score by using .best_params_
gridsearch.best_params_

#We can see that choosing 16 as value for k will yield the best predictive performance

#Predicting and finding RMSE
train_preds_grid = gridsearch.predict(X_train)
train_mse = mean_squared_error(y_train, train_preds_grid)
train_rmse = sqrt(train_mse)
test_preds_grid = gridsearch.predict(X_test)
test_mse = mean_squared_error(y_test, test_preds_grid)
test_rmse = sqrt(test_mse)
train_rmse

train_preds_grid

print("Accuracy:",metrics.accuracy_score(y_test, test_preds_grid))

test_rmse

#Now we can see the difference in RMSE values has become very less and the test error is better than before

#Further improvement can be done using bagging
#For further improvement, it would be possible to look for ways to wrangle the data differently or to find other external data sources.

#Compare Arbitrary K and GridSearchCV for K

"""DECISION TREE CLASSIFICATION"""

from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation

# Create Decision Tree classifer object
clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

#Finding Accuracy 

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))



#Optimizing the performance of decision tree


# Create Decision Tree classifer object
clf = DecisionTreeClassifier(criterion="entropy", max_depth=3)

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

#Here the classification rate has increased a bit

#Checking RMSE
mse = mean_squared_error(y_test, y_pred)
rmse = sqrt(mse)
rmse

#To plot decision tree, we need to install these two libraries

#!pip install graphviz
#!pip install pydotplus

confusion_matrix = metrics.confusion_matrix(y_test, y_pred)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])
import matplotlib.pyplot as plt
cm_display.plot()
plt.show()

from six import StringIO  
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus

feature_cols=['Sex','MaritalStatus', 'VehiclePrice', 'Deductible', 'DriverRating',
       'Days:Policy-Accident', 'PastNumberOfClaims', 'NumberOfSuppliments',
       'NumberOfCars']
dot_data = StringIO()
export_graphviz(clf, out_file=dot_data,filled=True, rounded=True,special_characters=True, feature_names = feature_cols,class_names=['0','1'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
graph.write_png('Fraudfound.png')
Image(graph.create_png())

#Decision trees are biased with imbalance dataset, 
#so for further improvement it is recommended to balance out the dataset before creating the decision tree.

"""SUPPORT VECTOR **MACHINE**"""

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=109) # 70% training and 30% test

#Import svm model
from sklearn import svm

#Create a svm Classifier
clf = svm.SVC(kernel='linear') # Linear Kernel

#Train the model using the training sets
clf.fit(X_train, y_train)

#Predict the response for test dataset
y_predx = clf.predict(X_test)

#Accuracy
print("Accuracy:",metrics.accuracy_score(y_test, y_predx))

#Checking RMSE
mse = mean_squared_error(y_test, y_predx)
rmse = sqrt(mse)
rmse

from sklearn.metrics import classification_report
print(classification_report(y_test,y_predx))

confusion_matrix = metrics.confusion_matrix(y_test, y_predx)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])
import matplotlib.pyplot as plt
cm_display.plot()
plt.show()

clf.support_vectors_

plt.scatter(clf.support_vectors_[:,0],clf.support_vectors_[:,1])



#LDA

from sklearn.model_selection import train_test_split
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis 
from sklearn import datasets
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

Dataframe.columns

#defining predictor and response variables
X=Dataframe[['Sex', 'MaritalStatus', 'VehiclePrice', 'Deductible', 'DriverRating',
       'Days:Policy-Accident', 'PastNumberOfClaims', 'NumberOfSuppliments',
       'NumberOfCars']]
y=Dataframe['FraudFound']

#Fitting LDA model
model = LinearDiscriminantAnalysis()
model.fit(X, y)

#Define method to evaluate model
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)

#evaluate model
scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
print(np.mean(scores))

#define new observation
new = [1, 3, 1, 2,2,4,2,1,9]

#predict which class the new observation belongs to
model.predict([new])